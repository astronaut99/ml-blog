{
  
    
        "post0": {
            "title": "Hello World - says TF!",
            "content": "import tensorflow as tf from tensorflow.keras import Sequential from tensorflow.keras.layers import Dense import numpy as np . Let&#39;s try and build a typical neural network . X = np.array([-1,0,1,2,3,4],dtype=float) y = np.array([-3,-1,1,3,5,7],dtype=float) model = Sequential([Dense(units=1,input_shape=[1])]) model.compile(optimizer=&#39;sgd&#39;,loss=&#39;mean_squared_error&#39;) model.fit(X,y,epochs=100) print(model.predict([10.0])) . Train on 6 samples Epoch 1/100 6/6 [==============================] - 0s 33ms/sample - loss: 12.7962 Epoch 2/100 6/6 [==============================] - 0s 333us/sample - loss: 10.2952 Epoch 3/100 6/6 [==============================] - 0s 333us/sample - loss: 8.3228 Epoch 4/100 6/6 [==============================] - 0s 166us/sample - loss: 6.7665 Epoch 5/100 6/6 [==============================] - 0s 671us/sample - loss: 5.5376 Epoch 6/100 6/6 [==============================] - 0s 166us/sample - loss: 4.5663 Epoch 7/100 6/6 [==============================] - 0s 673us/sample - loss: 3.7979 Epoch 8/100 6/6 [==============================] - 0s 333us/sample - loss: 3.1891 Epoch 9/100 6/6 [==============================] - 0s 263us/sample - loss: 2.7060 Epoch 10/100 6/6 [==============================] - 0s 179us/sample - loss: 2.3218 Epoch 11/100 6/6 [==============================] - 0s 360us/sample - loss: 2.0157 Epoch 12/100 6/6 [==============================] - 0s 725us/sample - loss: 1.7709 Epoch 13/100 6/6 [==============================] - 0s 413us/sample - loss: 1.5745 Epoch 14/100 6/6 [==============================] - 0s 526us/sample - loss: 1.4163 Epoch 15/100 6/6 [==============================] - 0s 841us/sample - loss: 1.2882 Epoch 16/100 6/6 [==============================] - 0s 215us/sample - loss: 1.1838 Epoch 17/100 6/6 [==============================] - 0s 335us/sample - loss: 1.0982 Epoch 18/100 6/6 [==============================] - 0s 334us/sample - loss: 1.0274 Epoch 19/100 6/6 [==============================] - 0s 333us/sample - loss: 0.9684 Epoch 20/100 6/6 [==============================] - 0s 337us/sample - loss: 0.9186 Epoch 21/100 6/6 [==============================] - 0s 871us/sample - loss: 0.8763 Epoch 22/100 6/6 [==============================] - 0s 184us/sample - loss: 0.8398 Epoch 23/100 6/6 [==============================] - 0s 333us/sample - loss: 0.8080 Epoch 24/100 6/6 [==============================] - 0s 333us/sample - loss: 0.7800 Epoch 25/100 6/6 [==============================] - 0s 627us/sample - loss: 0.7549 Epoch 26/100 6/6 [==============================] - 0s 332us/sample - loss: 0.7324 Epoch 27/100 6/6 [==============================] - 0s 333us/sample - loss: 0.7117 Epoch 28/100 6/6 [==============================] - 0s 334us/sample - loss: 0.6927 Epoch 29/100 6/6 [==============================] - 0s 331us/sample - loss: 0.6751 Epoch 30/100 6/6 [==============================] - 0s 334us/sample - loss: 0.6585 Epoch 31/100 6/6 [==============================] - 0s 750us/sample - loss: 0.6428 Epoch 32/100 6/6 [==============================] - 0s 376us/sample - loss: 0.6279 Epoch 33/100 6/6 [==============================] - 0s 185us/sample - loss: 0.6137 Epoch 34/100 6/6 [==============================] - 0s 338us/sample - loss: 0.6001 Epoch 35/100 6/6 [==============================] - 0s 352us/sample - loss: 0.5869 Epoch 36/100 6/6 [==============================] - 0s 497us/sample - loss: 0.5742 Epoch 37/100 6/6 [==============================] - 0s 333us/sample - loss: 0.5619 Epoch 38/100 6/6 [==============================] - 0s 332us/sample - loss: 0.5500 Epoch 39/100 6/6 [==============================] - 0s 499us/sample - loss: 0.5384 Epoch 40/100 6/6 [==============================] - 0s 220us/sample - loss: 0.5271 Epoch 41/100 6/6 [==============================] - 0s 332us/sample - loss: 0.5161 Epoch 42/100 6/6 [==============================] - 0s 331us/sample - loss: 0.5053 Epoch 43/100 6/6 [==============================] - 0s 333us/sample - loss: 0.4948 Epoch 44/100 6/6 [==============================] - 0s 499us/sample - loss: 0.4845 Epoch 45/100 6/6 [==============================] - 0s 601us/sample - loss: 0.4745 Epoch 46/100 6/6 [==============================] - 0s 332us/sample - loss: 0.4647 Epoch 47/100 6/6 [==============================] - 0s 338us/sample - loss: 0.4551 Epoch 48/100 6/6 [==============================] - 0s 332us/sample - loss: 0.4457 Epoch 49/100 6/6 [==============================] - 0s 356us/sample - loss: 0.4366 Epoch 50/100 6/6 [==============================] - 0s 503us/sample - loss: 0.4276 Epoch 51/100 6/6 [==============================] - 0s 383us/sample - loss: 0.4188 Epoch 52/100 6/6 [==============================] - 0s 331us/sample - loss: 0.4101 Epoch 53/100 6/6 [==============================] - 0s 333us/sample - loss: 0.4017 Epoch 54/100 6/6 [==============================] - 0s 529us/sample - loss: 0.3935 Epoch 55/100 6/6 [==============================] - 0s 496us/sample - loss: 0.3854 Epoch 56/100 6/6 [==============================] - 0s 333us/sample - loss: 0.3774 Epoch 57/100 6/6 [==============================] - 0s 332us/sample - loss: 0.3697 Epoch 58/100 6/6 [==============================] - 0s 378us/sample - loss: 0.3621 Epoch 59/100 6/6 [==============================] - 0s 502us/sample - loss: 0.3546 Epoch 60/100 6/6 [==============================] - 0s 180us/sample - loss: 0.3474 Epoch 61/100 6/6 [==============================] - 0s 232us/sample - loss: 0.3402 Epoch 62/100 6/6 [==============================] - 0s 355us/sample - loss: 0.3332 Epoch 63/100 6/6 [==============================] - 0s 502us/sample - loss: 0.3264 Epoch 64/100 6/6 [==============================] - 0s 693us/sample - loss: 0.3197 Epoch 65/100 6/6 [==============================] - 0s 394us/sample - loss: 0.3131 Epoch 66/100 6/6 [==============================] - 0s 167us/sample - loss: 0.3067 Epoch 67/100 6/6 [==============================] - 0s 333us/sample - loss: 0.3004 Epoch 68/100 6/6 [==============================] - 0s 609us/sample - loss: 0.2942 Epoch 69/100 6/6 [==============================] - 0s 350us/sample - loss: 0.2882 Epoch 70/100 6/6 [==============================] - 0s 339us/sample - loss: 0.2823 Epoch 71/100 6/6 [==============================] - 0s 333us/sample - loss: 0.2765 Epoch 72/100 6/6 [==============================] - 0s 361us/sample - loss: 0.2708 Epoch 73/100 6/6 [==============================] - 0s 824us/sample - loss: 0.2652 Epoch 74/100 6/6 [==============================] - 0s 268us/sample - loss: 0.2598 Epoch 75/100 6/6 [==============================] - 0s 333us/sample - loss: 0.2544 Epoch 76/100 6/6 [==============================] - 0s 170us/sample - loss: 0.2492 Epoch 77/100 6/6 [==============================] - 0s 596us/sample - loss: 0.2441 Epoch 78/100 6/6 [==============================] - 0s 333us/sample - loss: 0.2391 Epoch 79/100 6/6 [==============================] - 0s 169us/sample - loss: 0.2342 Epoch 80/100 6/6 [==============================] - 0s 504us/sample - loss: 0.2294 Epoch 81/100 6/6 [==============================] - 0s 369us/sample - loss: 0.2246 Epoch 82/100 6/6 [==============================] - 0s 753us/sample - loss: 0.2200 Epoch 83/100 6/6 [==============================] - 0s 166us/sample - loss: 0.2155 Epoch 84/100 6/6 [==============================] - 0s 333us/sample - loss: 0.2111 Epoch 85/100 6/6 [==============================] - 0s 333us/sample - loss: 0.2067 Epoch 86/100 6/6 [==============================] - 0s 501us/sample - loss: 0.2025 Epoch 87/100 6/6 [==============================] - 0s 348us/sample - loss: 0.1983 Epoch 88/100 6/6 [==============================] - 0s 327us/sample - loss: 0.1943 Epoch 89/100 6/6 [==============================] - 0s 332us/sample - loss: 0.1903 Epoch 90/100 6/6 [==============================] - 0s 548us/sample - loss: 0.1864 Epoch 91/100 6/6 [==============================] - 0s 689us/sample - loss: 0.1825 Epoch 92/100 6/6 [==============================] - 0s 332us/sample - loss: 0.1788 Epoch 93/100 6/6 [==============================] - 0s 166us/sample - loss: 0.1751 Epoch 94/100 6/6 [==============================] - 0s 381us/sample - loss: 0.1715 Epoch 95/100 6/6 [==============================] - 0s 1ms/sample - loss: 0.1680 Epoch 96/100 6/6 [==============================] - 0s 419us/sample - loss: 0.1645 Epoch 97/100 6/6 [==============================] - 0s 334us/sample - loss: 0.1612 Epoch 98/100 6/6 [==============================] - 0s 550us/sample - loss: 0.1579 Epoch 99/100 6/6 [==============================] - 0s 543us/sample - loss: 0.1546 Epoch 100/100 6/6 [==============================] - 0s 333us/sample - loss: 0.1514 [[17.864544]] .",
            "url": "https://astronaut99.github.io/ml-blog/2021/09/28/Hello-World.html",
            "relUrl": "/2021/09/28/Hello-World.html",
            "date": " • Sep 28, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://astronaut99.github.io/ml-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://astronaut99.github.io/ml-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://astronaut99.github.io/ml-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}