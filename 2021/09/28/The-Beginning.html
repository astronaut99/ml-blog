<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Hello World - says the Neuron! | fastpages</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Hello World - says the Neuron!" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<meta property="og:description" content="An easy to use blogging platform with support for Jupyter Notebooks." />
<link rel="canonical" href="https://astronaut99.github.io/ml-blog/2021/09/28/The-Beginning.html" />
<meta property="og:url" content="https://astronaut99.github.io/ml-blog/2021/09/28/The-Beginning.html" />
<meta property="og:site_name" content="fastpages" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-09-28T00:00:00-05:00" />
<script type="application/ld+json">
{"datePublished":"2021-09-28T00:00:00-05:00","url":"https://astronaut99.github.io/ml-blog/2021/09/28/The-Beginning.html","@type":"BlogPosting","headline":"Hello World - says the Neuron!","dateModified":"2021-09-28T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://astronaut99.github.io/ml-blog/2021/09/28/The-Beginning.html"},"description":"An easy to use blogging platform with support for Jupyter Notebooks.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/ml-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://astronaut99.github.io/ml-blog/feed.xml" title="fastpages" /><link rel="shortcut icon" type="image/x-icon" href="/ml-blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/ml-blog/">fastpages</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/ml-blog/about/">About Me</a><a class="page-link" href="/ml-blog/search/">Search</a><a class="page-link" href="/ml-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Hello World - says the Neuron!</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-09-28T00:00:00-05:00" itemprop="datePublished">
        Sep 28, 2021
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      14 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/astronaut99/ml-blog/tree/master/_notebooks/2021-09-28-The-Beginning.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/ml-blog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/astronaut99/ml-blog/master?filepath=_notebooks%2F2021-09-28-The-Beginning.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/ml-blog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/astronaut99/ml-blog/blob/master/_notebooks/2021-09-28-The-Beginning.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/ml-blog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-09-28-The-Beginning.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Let's try and build a typical neural network</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

<span class="n">X</span><span class="p">,</span><span class="n">y</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(array([-1.,  0.,  1.,  2.,  3.,  4.]), array([-3., -1.,  1.,  3.,  5.,  7.]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>Adding a Dense layer with a single neuron &amp; a raw matrix</em></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">layer0</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">input_shape</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span><span class="n">layer0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="mf">10.0</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[-16.16105]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>Compiling the model with a 'Stochastic Gradient Descent' Optimizer, where Stochastic -&gt; Random. And Gradient Descent is a mathematical way for the model to reach the Global Minimum.</li>
<li>Calculating the loss by taking the difference of squares of the actual &amp; predicted values.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;sgd&#39;</span><span class="p">,</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;mean_squared_error&#39;</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">epochs</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>
<details class="description">
      <summary class="btn btn-sm" data-open="Hide Output" data-close="Show Output"></summary>
        <p>
<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 6 samples
Epoch 1/250
6/6 [==============================] - 0s 40ms/sample - loss: 0.0015
Epoch 2/250
6/6 [==============================] - 0s 333us/sample - loss: 0.0015
Epoch 3/250
6/6 [==============================] - 0s 506us/sample - loss: 0.0015
Epoch 4/250
6/6 [==============================] - 0s 528us/sample - loss: 0.0014
Epoch 5/250
6/6 [==============================] - 0s 544us/sample - loss: 0.0014
Epoch 6/250
6/6 [==============================] - 0s 692us/sample - loss: 0.0014
Epoch 7/250
6/6 [==============================] - 0s 673us/sample - loss: 0.0014
Epoch 8/250
6/6 [==============================] - 0s 449us/sample - loss: 0.0013
Epoch 9/250
6/6 [==============================] - 0s 338us/sample - loss: 0.0013
Epoch 10/250
6/6 [==============================] - 0s 600us/sample - loss: 0.0013
Epoch 11/250
6/6 [==============================] - 0s 338us/sample - loss: 0.0012
Epoch 12/250
6/6 [==============================] - 0s 534us/sample - loss: 0.0012
Epoch 13/250
6/6 [==============================] - 0s 332us/sample - loss: 0.0012
Epoch 14/250
6/6 [==============================] - 0s 509us/sample - loss: 0.0012
Epoch 15/250
6/6 [==============================] - 0s 402us/sample - loss: 0.0011
Epoch 16/250
6/6 [==============================] - 0s 584us/sample - loss: 0.0011
Epoch 17/250
6/6 [==============================] - 0s 553us/sample - loss: 0.0011
Epoch 18/250
6/6 [==============================] - 0s 508us/sample - loss: 0.0011
Epoch 19/250
6/6 [==============================] - 0s 406us/sample - loss: 0.0011
Epoch 20/250
6/6 [==============================] - 0s 523us/sample - loss: 0.0010
Epoch 21/250
6/6 [==============================] - 0s 792us/sample - loss: 0.0010
Epoch 22/250
6/6 [==============================] - 0s 499us/sample - loss: 9.9368e-04
Epoch 23/250
6/6 [==============================] - 0s 499us/sample - loss: 9.7327e-04
Epoch 24/250
6/6 [==============================] - 0s 607us/sample - loss: 9.5328e-04
Epoch 25/250
6/6 [==============================] - 0s 311us/sample - loss: 9.3370e-04
Epoch 26/250
6/6 [==============================] - 0s 333us/sample - loss: 9.1452e-04
Epoch 27/250
6/6 [==============================] - 0s 610us/sample - loss: 8.9574e-04
Epoch 28/250
6/6 [==============================] - 0s 497us/sample - loss: 8.7734e-04
Epoch 29/250
6/6 [==============================] - 0s 333us/sample - loss: 8.5931e-04
Epoch 30/250
6/6 [==============================] - 0s 333us/sample - loss: 8.4166e-04
Epoch 31/250
6/6 [==============================] - 0s 697us/sample - loss: 8.2437e-04
Epoch 32/250
6/6 [==============================] - 0s 339us/sample - loss: 8.0744e-04
Epoch 33/250
6/6 [==============================] - 0s 553us/sample - loss: 7.9086e-04
Epoch 34/250
6/6 [==============================] - 0s 432us/sample - loss: 7.7461e-04
Epoch 35/250
6/6 [==============================] - 0s 586us/sample - loss: 7.5870e-04
Epoch 36/250
6/6 [==============================] - 0s 509us/sample - loss: 7.4311e-04
Epoch 37/250
6/6 [==============================] - 0s 550us/sample - loss: 7.2785e-04
Epoch 38/250
6/6 [==============================] - 0s 297us/sample - loss: 7.1290e-04
Epoch 39/250
6/6 [==============================] - 0s 332us/sample - loss: 6.9826e-04
Epoch 40/250
6/6 [==============================] - 0s 340us/sample - loss: 6.8392e-04
Epoch 41/250
6/6 [==============================] - 0s 332us/sample - loss: 6.6987e-04
Epoch 42/250
6/6 [==============================] - 0s 172us/sample - loss: 6.5611e-04
Epoch 43/250
6/6 [==============================] - 0s 341us/sample - loss: 6.4263e-04
Epoch 44/250
6/6 [==============================] - 0s 361us/sample - loss: 6.2943e-04
Epoch 45/250
6/6 [==============================] - 0s 179us/sample - loss: 6.1650e-04
Epoch 46/250
6/6 [==============================] - 0s 200us/sample - loss: 6.0384e-04
Epoch 47/250
6/6 [==============================] - 0s 379us/sample - loss: 5.9144e-04
Epoch 48/250
6/6 [==============================] - 0s 333us/sample - loss: 5.7928e-04
Epoch 49/250
6/6 [==============================] - 0s 333us/sample - loss: 5.6739e-04
Epoch 50/250
6/6 [==============================] - 0s 370us/sample - loss: 5.5573e-04
Epoch 51/250
6/6 [==============================] - 0s 167us/sample - loss: 5.4432e-04
Epoch 52/250
6/6 [==============================] - 0s 333us/sample - loss: 5.3314e-04
Epoch 53/250
6/6 [==============================] - 0s 332us/sample - loss: 5.2219e-04
Epoch 54/250
6/6 [==============================] - 0s 338us/sample - loss: 5.1146e-04
Epoch 55/250
6/6 [==============================] - 0s 525us/sample - loss: 5.0095e-04
Epoch 56/250
6/6 [==============================] - 0s 349us/sample - loss: 4.9066e-04
Epoch 57/250
6/6 [==============================] - 0s 353us/sample - loss: 4.8058e-04
Epoch 58/250
6/6 [==============================] - 0s 373us/sample - loss: 4.7071e-04
Epoch 59/250
6/6 [==============================] - 0s 379us/sample - loss: 4.6104e-04
Epoch 60/250
6/6 [==============================] - 0s 505us/sample - loss: 4.5157e-04
Epoch 61/250
6/6 [==============================] - 0s 338us/sample - loss: 4.4230e-04
Epoch 62/250
6/6 [==============================] - 0s 346us/sample - loss: 4.3321e-04
Epoch 63/250
6/6 [==============================] - 0s 332us/sample - loss: 4.2431e-04
Epoch 64/250
6/6 [==============================] - 0s 504us/sample - loss: 4.1560e-04
Epoch 65/250
6/6 [==============================] - 0s 500us/sample - loss: 4.0707e-04
Epoch 66/250
6/6 [==============================] - 0s 498us/sample - loss: 3.9870e-04
Epoch 67/250
6/6 [==============================] - 0s 209us/sample - loss: 3.9051e-04
Epoch 68/250
6/6 [==============================] - 0s 332us/sample - loss: 3.8249e-04
Epoch 69/250
6/6 [==============================] - 0s 577us/sample - loss: 3.7464e-04
Epoch 70/250
6/6 [==============================] - 0s 500us/sample - loss: 3.6694e-04
Epoch 71/250
6/6 [==============================] - 0s 333us/sample - loss: 3.5940e-04
Epoch 72/250
6/6 [==============================] - 0s 332us/sample - loss: 3.5202e-04
Epoch 73/250
6/6 [==============================] - 0s 340us/sample - loss: 3.4479e-04
Epoch 74/250
6/6 [==============================] - 0s 332us/sample - loss: 3.3771e-04
Epoch 75/250
6/6 [==============================] - 0s 864us/sample - loss: 3.3077e-04
Epoch 76/250
6/6 [==============================] - 0s 333us/sample - loss: 3.2398e-04
Epoch 77/250
6/6 [==============================] - 0s 166us/sample - loss: 3.1732e-04
Epoch 78/250
6/6 [==============================] - 0s 514us/sample - loss: 3.1080e-04
Epoch 79/250
6/6 [==============================] - 0s 564us/sample - loss: 3.0442e-04
Epoch 80/250
6/6 [==============================] - 0s 332us/sample - loss: 2.9817e-04
Epoch 81/250
6/6 [==============================] - 0s 166us/sample - loss: 2.9204e-04
Epoch 82/250
6/6 [==============================] - 0s 186us/sample - loss: 2.8604e-04
Epoch 83/250
6/6 [==============================] - 0s 171us/sample - loss: 2.8017e-04
Epoch 84/250
6/6 [==============================] - 0s 327us/sample - loss: 2.7441e-04
Epoch 85/250
6/6 [==============================] - 0s 515us/sample - loss: 2.6878e-04
Epoch 86/250
6/6 [==============================] - 0s 160us/sample - loss: 2.6326e-04
Epoch 87/250
6/6 [==============================] - 0s 174us/sample - loss: 2.5785e-04
Epoch 88/250
6/6 [==============================] - 0s 334us/sample - loss: 2.5255e-04
Epoch 89/250
6/6 [==============================] - 0s 333us/sample - loss: 2.4737e-04
Epoch 90/250
6/6 [==============================] - 0s 534us/sample - loss: 2.4229e-04
Epoch 91/250
6/6 [==============================] - 0s 166us/sample - loss: 2.3731e-04
Epoch 92/250
6/6 [==============================] - 0s 179us/sample - loss: 2.3243e-04
Epoch 93/250
6/6 [==============================] - 0s 373us/sample - loss: 2.2766e-04
Epoch 94/250
6/6 [==============================] - 0s 200us/sample - loss: 2.2298e-04
Epoch 95/250
6/6 [==============================] - 0s 339us/sample - loss: 2.1840e-04
Epoch 96/250
6/6 [==============================] - 0s 358us/sample - loss: 2.1391e-04
Epoch 97/250
6/6 [==============================] - 0s 679us/sample - loss: 2.0952e-04
Epoch 98/250
6/6 [==============================] - 0s 391us/sample - loss: 2.0522e-04
Epoch 99/250
6/6 [==============================] - 0s 332us/sample - loss: 2.0100e-04
Epoch 100/250
6/6 [==============================] - 0s 333us/sample - loss: 1.9687e-04
Epoch 101/250
6/6 [==============================] - 0s 333us/sample - loss: 1.9283e-04
Epoch 102/250
6/6 [==============================] - 0s 188us/sample - loss: 1.8887e-04
Epoch 103/250
6/6 [==============================] - 0s 513us/sample - loss: 1.8499e-04
Epoch 104/250
6/6 [==============================] - 0s 395us/sample - loss: 1.8119e-04
Epoch 105/250
6/6 [==============================] - 0s 543us/sample - loss: 1.7747e-04
Epoch 106/250
6/6 [==============================] - 0s 336us/sample - loss: 1.7382e-04
Epoch 107/250
6/6 [==============================] - 0s 333us/sample - loss: 1.7025e-04
Epoch 108/250
6/6 [==============================] - 0s 166us/sample - loss: 1.6675e-04
Epoch 109/250
6/6 [==============================] - 0s 173us/sample - loss: 1.6333e-04
Epoch 110/250
6/6 [==============================] - 0s 676us/sample - loss: 1.5997e-04
Epoch 111/250
6/6 [==============================] - 0s 175us/sample - loss: 1.5669e-04
Epoch 112/250
6/6 [==============================] - 0s 333us/sample - loss: 1.5347e-04
Epoch 113/250
6/6 [==============================] - 0s 333us/sample - loss: 1.5032e-04
Epoch 114/250
6/6 [==============================] - 0s 180us/sample - loss: 1.4723e-04
Epoch 115/250
6/6 [==============================] - 0s 166us/sample - loss: 1.4420e-04
Epoch 116/250
6/6 [==============================] - 0s 340us/sample - loss: 1.4124e-04
Epoch 117/250
6/6 [==============================] - 0s 673us/sample - loss: 1.3834e-04
Epoch 118/250
6/6 [==============================] - 0s 333us/sample - loss: 1.3550e-04
Epoch 119/250
6/6 [==============================] - 0s 166us/sample - loss: 1.3272e-04
Epoch 120/250
6/6 [==============================] - 0s 331us/sample - loss: 1.2999e-04
Epoch 121/250
6/6 [==============================] - 0s 189us/sample - loss: 1.2732e-04
Epoch 122/250
6/6 [==============================] - 0s 332us/sample - loss: 1.2470e-04
Epoch 123/250
6/6 [==============================] - 0s 333us/sample - loss: 1.2214e-04
Epoch 124/250
6/6 [==============================] - 0s 332us/sample - loss: 1.1963e-04
Epoch 125/250
6/6 [==============================] - 0s 499us/sample - loss: 1.1718e-04
Epoch 126/250
6/6 [==============================] - 0s 665us/sample - loss: 1.1477e-04
Epoch 127/250
6/6 [==============================] - 0s 336us/sample - loss: 1.1241e-04
Epoch 128/250
6/6 [==============================] - 0s 333us/sample - loss: 1.1010e-04
Epoch 129/250
6/6 [==============================] - 0s 337us/sample - loss: 1.0784e-04
Epoch 130/250
6/6 [==============================] - 0s 166us/sample - loss: 1.0563e-04
Epoch 131/250
6/6 [==============================] - 0s 172us/sample - loss: 1.0346e-04
Epoch 132/250
6/6 [==============================] - 0s 336us/sample - loss: 1.0133e-04
Epoch 133/250
6/6 [==============================] - 0s 196us/sample - loss: 9.9251e-05
Epoch 134/250
6/6 [==============================] - 0s 338us/sample - loss: 9.7212e-05
Epoch 135/250
6/6 [==============================] - 0s 374us/sample - loss: 9.5214e-05
Epoch 136/250
6/6 [==============================] - 0s 332us/sample - loss: 9.3259e-05
Epoch 137/250
6/6 [==============================] - 0s 380us/sample - loss: 9.1342e-05
Epoch 138/250
6/6 [==============================] - 0s 186us/sample - loss: 8.9467e-05
Epoch 139/250
6/6 [==============================] - 0s 441us/sample - loss: 8.7628e-05
Epoch 140/250
6/6 [==============================] - 0s 333us/sample - loss: 8.5828e-05
Epoch 141/250
6/6 [==============================] - 0s 166us/sample - loss: 8.4066e-05
Epoch 142/250
6/6 [==============================] - 0s 166us/sample - loss: 8.2339e-05
Epoch 143/250
6/6 [==============================] - 0s 166us/sample - loss: 8.0648e-05
Epoch 144/250
6/6 [==============================] - 0s 180us/sample - loss: 7.8990e-05
Epoch 145/250
6/6 [==============================] - 0s 377us/sample - loss: 7.7368e-05
Epoch 146/250
6/6 [==============================] - 0s 500us/sample - loss: 7.5780e-05
Epoch 147/250
6/6 [==============================] - 0s 332us/sample - loss: 7.4223e-05
Epoch 148/250
6/6 [==============================] - 0s 326us/sample - loss: 7.2699e-05
Epoch 149/250
6/6 [==============================] - 0s 332us/sample - loss: 7.1205e-05
Epoch 150/250
6/6 [==============================] - 0s 333us/sample - loss: 6.9743e-05
Epoch 151/250
6/6 [==============================] - 0s 225us/sample - loss: 6.8309e-05
Epoch 152/250
6/6 [==============================] - 0s 338us/sample - loss: 6.6906e-05
Epoch 153/250
6/6 [==============================] - 0s 332us/sample - loss: 6.5531e-05
Epoch 154/250
6/6 [==============================] - 0s 338us/sample - loss: 6.4187e-05
Epoch 155/250
6/6 [==============================] - 0s 338us/sample - loss: 6.2868e-05
Epoch 156/250
6/6 [==============================] - 0s 361us/sample - loss: 6.1577e-05
Epoch 157/250
6/6 [==============================] - 0s 582us/sample - loss: 6.0313e-05
Epoch 158/250
6/6 [==============================] - 0s 513us/sample - loss: 5.9074e-05
Epoch 159/250
6/6 [==============================] - 0s 181us/sample - loss: 5.7861e-05
Epoch 160/250
6/6 [==============================] - 0s 338us/sample - loss: 5.6672e-05
Epoch 161/250
6/6 [==============================] - 0s 330us/sample - loss: 5.5508e-05
Epoch 162/250
6/6 [==============================] - 0s 338us/sample - loss: 5.4367e-05
Epoch 163/250
6/6 [==============================] - 0s 378us/sample - loss: 5.3251e-05
Epoch 164/250
6/6 [==============================] - 0s 170us/sample - loss: 5.2157e-05
Epoch 165/250
6/6 [==============================] - 0s 327us/sample - loss: 5.1085e-05
Epoch 166/250
6/6 [==============================] - 0s 332us/sample - loss: 5.0036e-05
Epoch 167/250
6/6 [==============================] - 0s 171us/sample - loss: 4.9009e-05
Epoch 168/250
6/6 [==============================] - 0s 333us/sample - loss: 4.8002e-05
Epoch 169/250
6/6 [==============================] - 0s 667us/sample - loss: 4.7016e-05
Epoch 170/250
6/6 [==============================] - 0s 349us/sample - loss: 4.6051e-05
Epoch 171/250
6/6 [==============================] - 0s 332us/sample - loss: 4.5105e-05
Epoch 172/250
6/6 [==============================] - 0s 332us/sample - loss: 4.4178e-05
Epoch 173/250
6/6 [==============================] - 0s 166us/sample - loss: 4.3270e-05
Epoch 174/250
6/6 [==============================] - 0s 332us/sample - loss: 4.2383e-05
Epoch 175/250
6/6 [==============================] - 0s 166us/sample - loss: 4.1511e-05
Epoch 176/250
6/6 [==============================] - 0s 332us/sample - loss: 4.0658e-05
Epoch 177/250
6/6 [==============================] - 0s 166us/sample - loss: 3.9824e-05
Epoch 178/250
6/6 [==============================] - 0s 166us/sample - loss: 3.9005e-05
Epoch 179/250
6/6 [==============================] - 0s 333us/sample - loss: 3.8204e-05
Epoch 180/250
6/6 [==============================] - 0s 499us/sample - loss: 3.7420e-05
Epoch 181/250
6/6 [==============================] - 0s 337us/sample - loss: 3.6651e-05
Epoch 182/250
6/6 [==============================] - 0s 333us/sample - loss: 3.5898e-05
Epoch 183/250
6/6 [==============================] - 0s 332us/sample - loss: 3.5160e-05
Epoch 184/250
6/6 [==============================] - 0s 333us/sample - loss: 3.4438e-05
Epoch 185/250
6/6 [==============================] - 0s 332us/sample - loss: 3.3732e-05
Epoch 186/250
6/6 [==============================] - 0s 197us/sample - loss: 3.3039e-05
Epoch 187/250
6/6 [==============================] - 0s 209us/sample - loss: 3.2359e-05
Epoch 188/250
6/6 [==============================] - 0s 337us/sample - loss: 3.1695e-05
Epoch 189/250
6/6 [==============================] - 0s 333us/sample - loss: 3.1044e-05
Epoch 190/250
6/6 [==============================] - 0s 179us/sample - loss: 3.0406e-05
Epoch 191/250
6/6 [==============================] - 0s 332us/sample - loss: 2.9782e-05
Epoch 192/250
6/6 [==============================] - 0s 339us/sample - loss: 2.9170e-05
Epoch 193/250
6/6 [==============================] - 0s 171us/sample - loss: 2.8571e-05
Epoch 194/250
6/6 [==============================] - 0s 166us/sample - loss: 2.7985e-05
Epoch 195/250
6/6 [==============================] - 0s 406us/sample - loss: 2.7409e-05
Epoch 196/250
6/6 [==============================] - 0s 499us/sample - loss: 2.6846e-05
Epoch 197/250
6/6 [==============================] - 0s 333us/sample - loss: 2.6295e-05
Epoch 198/250
6/6 [==============================] - 0s 332us/sample - loss: 2.5754e-05
Epoch 199/250
6/6 [==============================] - 0s 171us/sample - loss: 2.5226e-05
Epoch 200/250
6/6 [==============================] - 0s 177us/sample - loss: 2.4707e-05
Epoch 201/250
6/6 [==============================] - 0s 339us/sample - loss: 2.4199e-05
Epoch 202/250
6/6 [==============================] - 0s 332us/sample - loss: 2.3702e-05
Epoch 203/250
6/6 [==============================] - 0s 332us/sample - loss: 2.3216e-05
Epoch 204/250
6/6 [==============================] - 0s 192us/sample - loss: 2.2738e-05
Epoch 205/250
6/6 [==============================] - 0s 333us/sample - loss: 2.2272e-05
Epoch 206/250
6/6 [==============================] - 0s 332us/sample - loss: 2.1814e-05
Epoch 207/250
6/6 [==============================] - 0s 336us/sample - loss: 2.1366e-05
Epoch 208/250
6/6 [==============================] - 0s 332us/sample - loss: 2.0927e-05
Epoch 209/250
6/6 [==============================] - 0s 535us/sample - loss: 2.0496e-05
Epoch 210/250
6/6 [==============================] - 0s 333us/sample - loss: 2.0076e-05
Epoch 211/250
6/6 [==============================] - 0s 167us/sample - loss: 1.9663e-05
Epoch 212/250
6/6 [==============================] - 0s 342us/sample - loss: 1.9260e-05
Epoch 213/250
6/6 [==============================] - 0s 216us/sample - loss: 1.8864e-05
Epoch 214/250
6/6 [==============================] - 0s 332us/sample - loss: 1.8476e-05
Epoch 215/250
6/6 [==============================] - 0s 333us/sample - loss: 1.8097e-05
Epoch 216/250
6/6 [==============================] - 0s 341us/sample - loss: 1.7725e-05
Epoch 217/250
6/6 [==============================] - 0s 333us/sample - loss: 1.7361e-05
Epoch 218/250
6/6 [==============================] - 0s 168us/sample - loss: 1.7004e-05
Epoch 219/250
6/6 [==============================] - 0s 332us/sample - loss: 1.6655e-05
Epoch 220/250
6/6 [==============================] - 0s 166us/sample - loss: 1.6313e-05
Epoch 221/250
6/6 [==============================] - 0s 166us/sample - loss: 1.5978e-05
Epoch 222/250
6/6 [==============================] - 0s 391us/sample - loss: 1.5650e-05
Epoch 223/250
6/6 [==============================] - 0s 500us/sample - loss: 1.5328e-05
Epoch 224/250
6/6 [==============================] - 0s 219us/sample - loss: 1.5013e-05
Epoch 225/250
6/6 [==============================] - 0s 327us/sample - loss: 1.4705e-05
Epoch 226/250
6/6 [==============================] - 0s 330us/sample - loss: 1.4403e-05
Epoch 227/250
6/6 [==============================] - 0s 333us/sample - loss: 1.4107e-05
Epoch 228/250
6/6 [==============================] - 0s 179us/sample - loss: 1.3818e-05
Epoch 229/250
6/6 [==============================] - 0s 333us/sample - loss: 1.3533e-05
Epoch 230/250
6/6 [==============================] - 0s 333us/sample - loss: 1.3256e-05
Epoch 231/250
6/6 [==============================] - 0s 333us/sample - loss: 1.2983e-05
Epoch 232/250
6/6 [==============================] - 0s 166us/sample - loss: 1.2717e-05
Epoch 233/250
6/6 [==============================] - 0s 193us/sample - loss: 1.2456e-05
Epoch 234/250
6/6 [==============================] - 0s 166us/sample - loss: 1.2200e-05
Epoch 235/250
6/6 [==============================] - 0s 338us/sample - loss: 1.1949e-05
Epoch 236/250
6/6 [==============================] - 0s 493us/sample - loss: 1.1703e-05
Epoch 237/250
6/6 [==============================] - 0s 338us/sample - loss: 1.1463e-05
Epoch 238/250
6/6 [==============================] - 0s 166us/sample - loss: 1.1228e-05
Epoch 239/250
6/6 [==============================] - 0s 499us/sample - loss: 1.0997e-05
Epoch 240/250
6/6 [==============================] - 0s 359us/sample - loss: 1.0771e-05
Epoch 241/250
6/6 [==============================] - 0s 166us/sample - loss: 1.0550e-05
Epoch 242/250
6/6 [==============================] - 0s 166us/sample - loss: 1.0333e-05
Epoch 243/250
6/6 [==============================] - 0s 332us/sample - loss: 1.0121e-05
Epoch 244/250
6/6 [==============================] - 0s 332us/sample - loss: 9.9131e-06
Epoch 245/250
6/6 [==============================] - 0s 169us/sample - loss: 9.7095e-06
Epoch 246/250
6/6 [==============================] - 0s 333us/sample - loss: 9.5102e-06
Epoch 247/250
6/6 [==============================] - 0s 346us/sample - loss: 9.3147e-06
Epoch 248/250
6/6 [==============================] - 0s 166us/sample - loss: 9.1239e-06
Epoch 249/250
6/6 [==============================] - 0s 333us/sample - loss: 8.9360e-06
Epoch 250/250
6/6 [==============================] - 0s 166us/sample - loss: 8.7528e-06
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;tensorflow.python.keras.callbacks.History at 0x221dd2a8d30&gt;</pre>
</div>

</div>

</div>
</div>
</p>
    </details>
</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><em>Making a Prediction</em></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="mi">10</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[18.991367]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><strong>Seeing what the network learned</strong></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Here&#39;s what I learned: </span><span class="si">{</span><span class="n">layer0</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Here&#39;s what I learned: [array([[1.9987489]], dtype=float32), array([-0.99612147], dtype=float32)]
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Thus the learned Values were : Y = </span><span class="si">{</span><span class="n">layer0</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">X - </span><span class="si">{</span><span class="n">layer0</span><span class="o">.</span><span class="n">get_weights</span><span class="p">()[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Thus the learned Values were : Y = 1.9987488985061646X - -0.9961214661598206
</pre>
</div>
</div>

</div>
</div>

</div>
    

</div>



  </div><a class="u-url" href="/ml-blog/2021/09/28/The-Beginning.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/ml-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/ml-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/ml-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/ml-blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/ml-blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
